{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/everestso/Fall24Spring25/blob/main/DeepNetworks_DiamondsInColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4BKVI4dEyI0"
      },
      "source": [
        "# Deep Learning w/ Diamonds\n",
        "\n",
        "https://www.kaggle.com/datasets/shivam2503/diamonds\n",
        "\n",
        "## Provides examples using a variety of Deep Learning APIs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AJ-SyI7xXHPY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77FkUeKH_nJ6",
        "outputId": "a055bf72-0d6c-43ec-c397-64c5980fdc05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-OzEC9axnc2fTMMcHCXnBkQzypluJLLG\n",
            "To: /content/diamonds.csv\n",
            "\r  0% 0.00/2.57M [00:00<?, ?B/s]\r100% 2.57M/2.57M [00:00<00:00, 160MB/s]\n",
            "(53940, 10)\n"
          ]
        }
      ],
      "source": [
        "!gdown 1-OzEC9axnc2fTMMcHCXnBkQzypluJLLG\n",
        "\n",
        "file_name = 'diamonds.csv'\n",
        "\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "df.head()\n",
        "print (df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ygjMjWlX-7I",
        "outputId": "088b031e-4010-4fad-9200-cd04ae1e843a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diamond_sample.shape=(53940, 10)\n",
            "X.columns=Index(['carat', 'depth', 'table', 'x', 'y', 'z'], dtype='object'), X.shape=(53940, 6)\n",
            "   carat  depth  table     x     y     z\n",
            "0   0.23   61.5   55.0  3.95  3.98  2.43\n",
            "1   0.21   59.8   61.0  3.89  3.84  2.31\n",
            "2   0.23   56.9   65.0  4.05  4.07  2.31\n",
            "Index(['price'], dtype='object')\n",
            "y.iloc[:3]=   price\n",
            "0    326\n",
            "1    326\n",
            "2    327\n"
          ]
        }
      ],
      "source": [
        "#diamond_sample = df.sample(30, random_state=12)\n",
        "diamond_sample = df.copy()\n",
        "print(f\"{diamond_sample.shape=}\")\n",
        "\n",
        "# Create a dataframe X containing all the features except cut, color, clarity, and price\n",
        "X = diamond_sample.drop(['cut', 'color', 'clarity', 'price'], axis=1)\n",
        "print(f\"{X.columns=}, {X.shape=}\")\n",
        "print(f\"{X[:3]}\")\n",
        "\n",
        "\n",
        "# Create a dataframe y containing the feature price\n",
        "y = diamond_sample[['price']]\n",
        "print(f\"{y.columns}\")\n",
        "print(f\"{y.iloc[:3]=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzaWzfkwhaGm"
      },
      "source": [
        "## Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWRzU7aWhZFW",
        "outputId": "62b6d702-e469-43f8-98b7-5beb10e071e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.55116139 -0.87705508 -0.20503673  0.79886224  0.74694202  0.64630735]\n",
            " [-0.84330851  0.31649342 -1.10028304 -0.87788733 -0.83947701 -0.81830926]\n",
            " [-0.82218018 -2.07060358  2.03307906 -0.77086076 -0.77012536 -0.95913778]\n",
            " ...\n",
            " [-1.05459183  0.24628469 -1.10028304 -1.27923696 -1.22091109 -1.21262911]\n",
            " [ 0.4243914   0.80795457 -0.20503673  0.55805246  0.50421124  0.6322245 ]\n",
            " [-0.18833022  1.08878951 -0.20503673 -0.07518807 -0.04193302  0.06891042]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Define a standardization scaler to transform values\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split data into train and test sets\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "Transform = StandardScaler()\n",
        "\n",
        "# Apply scaler\n",
        "Xtrain_scaled = Transform.fit_transform(Xtrain)\n",
        "Xtest_scaled = Transform.transform(Xtest)\n",
        "\n",
        "print  (Xtrain_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjPL-d4uilpp",
        "outputId": "0515d82d-3b40-4014-a54d-9a24199c1e20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transform.mean_ = [ 0.79913634 61.74921076 57.45805657  5.73430213  5.73837147  3.54106785]\n",
            "Transform.scale_ = [0.47329813 1.42432419 2.23402205 1.12121693 1.15354138 0.71008344]\n",
            "Xtrain.columns[0]='carat', Transform.mean_[0]=0.7991363419672652, Transform.scale_[0]=0.47329813202512444, np.std(Xtrain[Xtrain.columns[0]])=0.47329813202512444\n",
            "Xtrain.iloc[0,0]=1.06, (Xtrain.iloc[0,0]-Transform.mean_[0])/Transform.scale_[0]=0.5511613935946977, Xtrain_scaled[0][0]=0.5511613935946977\n",
            "np.mean(Xtrain, axis=0)=carat     0.799136\n",
            "depth    61.749211\n",
            "table    57.458057\n",
            "x         5.734302\n",
            "y         5.738371\n",
            "z         3.541068\n",
            "dtype: float64\n",
            "np.std(Xtrain, axis=0)=carat    0.473298\n",
            "depth    1.424324\n",
            "table    2.234022\n",
            "x        1.121217\n",
            "y        1.153541\n",
            "z        0.710083\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# prompt: Print the transform formula details\n",
        "\n",
        "print(f\"Transform.mean_ = {Transform.mean_}\")\n",
        "print(f\"Transform.scale_ = {Transform.scale_}\")\n",
        "\n",
        "print (f\"{Xtrain.columns[0]=}, {Transform.mean_[0]=}, {Transform.scale_[0]=}, {np.std(Xtrain[Xtrain.columns[0]])=}\")\n",
        "print (f\"{Xtrain.iloc[0,0]=}, {(Xtrain.iloc[0,0]-Transform.mean_[0])/Transform.scale_[0]=}, {Xtrain_scaled[0][0]=}\")\n",
        "print (f\"{np.mean(Xtrain, axis=0)=}\")\n",
        "print (f\"{np.std(Xtrain, axis=0)=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDDB5aCUY6wq"
      },
      "source": [
        "# Now ML Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kdCxrio9Y8-R"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oacKAssdY_4x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = 'tensorflow'\n",
        "\n",
        "# The backend must be set before importing keras, not after\n",
        "import keras\n",
        "keras.utils.set_random_seed(812)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ATHl21aJYA7o"
      },
      "outputs": [],
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "0rNgWYkSYFsX",
        "outputId": "4526a50f-e271-4850-92fd-f1b205c5c3ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,009</span> (168.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43,009\u001b[0m (168.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,009</span> (168.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m43,009\u001b[0m (168.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# Define the model structure using keras.Sequential. The input layer has shape=(6, ), hidden layer 1 has\n",
        "# 256 nodes and relu activation, hidden layer 2 had 128 nodes and linear activation, hidden layer 3 has\n",
        "# 64 nodes and linear activation, and the output layer has 1 node (for regression) and linear activation\n",
        "\n",
        "# Your code here\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(6,)),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='linear'),\n",
        "])\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxubrNbyYNzh",
        "outputId": "1675dd0e-98b2-40e1-cc5c-f2b720850fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: [[2741.56 ]\n",
            " [4768.363]\n",
            " [ 994.53 ]]\n",
            "Actual values:        price\n",
            "782     2860\n",
            "10082   4711\n",
            "32973    811\n"
          ]
        }
      ],
      "source": [
        "# Specify training choices using the compile method, with optimizer='Adam', loss='MeanSquaredError',\n",
        "# metrics='mse'\n",
        "# Your code here\n",
        "model.compile(optimizer='Adam', loss='MeanSquaredError', metrics=['mse'])\n",
        "# Train the model with a batch size of 100, 5 epochs, validation_split=0.1, and verbose=0\n",
        "# Your code here\n",
        "model.fit(Xtrain, ytrain, batch_size=100, epochs=130, validation_split=0.1, verbose=0)\n",
        "\n",
        "predictions = model.predict(Xtest[:3], verbose=0)\n",
        "print('Predictions:', predictions.round(3))\n",
        "print('Actual values:', ytest[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x639kZLPYXs5",
        "outputId": "2e51430c-f241-4b97-cbbf-082dfd6c46b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "out=[(2741.56, 2860), (4768.36, 4711), (994.53, 811)]\n"
          ]
        }
      ],
      "source": [
        "out = [(pHat, p) for (pHat, p) in zip(np.ravel(predictions.round(2)), np.ravel(ytest[:3]))]\n",
        "print (f\"{out=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQVDO3iKYauh",
        "outputId": "bb157d53-a932-43cc-89ae-f9ed848e44bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xtrain.shape=(37758, 6)\n",
            "\u001b[1m1180/1180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "R-squared Test: 0.8693997039388022\n",
            "\u001b[1m506/506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "R-squared Test: 0.8681906546274586\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Assuming 'model' is your trained Keras model, 'Xtest' is your test data, and 'ytest' are the true target values\n",
        "print (f\"{Xtrain.shape=}\")\n",
        "y_predicted = model.predict(Xtrain)\n",
        "r2 = r2_score(ytrain, y_predicted)\n",
        "print(\"R-squared Test:\", r2)\n",
        "\n",
        "y_predicted = model.predict(Xtest)\n",
        "r2 = r2_score(ytest, y_predicted)\n",
        "print(\"R-squared Test:\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uaIix0a2O2p"
      },
      "source": [
        "# Now pyTorch w/ No Keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIgUbmwB2Qsp",
        "outputId": "0d2815f7-5460-439d-df4b-cd9a644737db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: [[2340.513]\n",
            " [4241.342]\n",
            " [ 830.778]]\n",
            "Actual values:        price\n",
            "782     2860\n",
            "10082   4711\n",
            "32973    811\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "status = 10\n",
        "\n",
        "# Define the model structure using nn.Sequential\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(6, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 1)\n",
        ")\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "Xtrain_tensor = torch.tensor(Xtrain.values, dtype=torch.float32)\n",
        "ytrain_tensor = torch.tensor(ytrain.values, dtype=torch.float32)\n",
        "\n",
        "# Train the model\n",
        "epochs = 130\n",
        "batch_size = 100\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "  for i in range(0, len(Xtrain_tensor), batch_size):\n",
        "    # Get batch of data\n",
        "    Xbatch = Xtrain_tensor[i:i+batch_size]\n",
        "    ybatch = ytrain_tensor[i:i+batch_size]\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(Xbatch)\n",
        "    loss = criterion(outputs, ybatch)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if ((epoch+1)%10==0):\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Training time ({epoch+1}): {elapsed_time=} seconds\")\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Training time ({epoch+1}): {elapsed_time=} seconds\")\n",
        "\n",
        "# Convert test data to PyTorch tensors\n",
        "Xtest_tensor = torch.tensor(Xtest.values, dtype=torch.float32)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model(Xtest_tensor[:3])\n",
        "\n",
        "# Convert predictions to numpy array\n",
        "predictions = predictions.detach().numpy()\n",
        "\n",
        "print('Predictions:', predictions.round(3))\n",
        "print('Actual values:', ytest[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URtCXoaw2Yyr",
        "outputId": "f0c4a10b-1f5f-4b4a-dc00-21b23759f0c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xtrain.shape=(37758, 6)\n",
            "R-squared Train: 0.8771908974385489\n",
            "R-squared Test: 0.8777515290649166\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Assuming 'model' is your trained Keras model, 'Xtest' is your test data, and 'ytest' are the true target values\n",
        "print (f\"{Xtrain.shape=}\")\n",
        "\n",
        "# Convert Xtrain to PyTorch tensor\n",
        "Xtrain_tensor = torch.tensor(Xtrain.values, dtype=torch.float32)\n",
        "y_predicted = model(Xtrain_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.detach().numpy()\n",
        "r2 = r2_score(ytrain, y_predicted)\n",
        "print(\"R-squared Train:\", r2)\n",
        "\n",
        "# Convert Xtest to PyTorch tensor\n",
        "Xtest_tensor = torch.tensor(Xtest.values, dtype=torch.float32)\n",
        "y_predicted = model(Xtest_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.detach().numpy()\n",
        "r2 = r2_score(ytest, y_predicted)\n",
        "print(\"R-squared Test:\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9d0luO6CJZl"
      },
      "source": [
        "# Now full pyTorch API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGfCZKxgCNv-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the model structure using a class\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the model\n",
        "model = Net()\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE8xPChNCXWY"
      },
      "outputs": [],
      "source": [
        "# Convert data to PyTorch tensors\n",
        "Xtrain_tensor = torch.tensor(Xtrain.values, dtype=torch.float32)\n",
        "ytrain_tensor = torch.tensor(ytrain.values, dtype=torch.float32)\n",
        "\n",
        "# Train the model\n",
        "epochs = 130\n",
        "batch_size = 100\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "  for i in range(0, len(Xtrain_tensor), batch_size):\n",
        "    # Get batch of data\n",
        "    Xbatch = Xtrain_tensor[i:i+batch_size]\n",
        "    ybatch = ytrain_tensor[i:i+batch_size]\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(Xbatch)\n",
        "    loss = criterion(outputs, ybatch)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  if ((epoch+1)%10==0):\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Training time ({epoch+1}): {elapsed_time=} seconds\")\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Training time ({epoch+1}): {elapsed_time=} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhzmR3CKCjRg",
        "outputId": "a6b1cbb3-415b-47c0-c3b2-41fd2a7074e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xtrain.shape=(37758, 6)\n",
            "R-squared Train: 0.8821964244680871\n",
            "R-squared Test: 0.881390009647816\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Assuming 'model' is your trained PyTorch model, 'Xtest' is your test data, and 'ytest' are the true target values\n",
        "print (f\"{Xtrain.shape=}\")\n",
        "\n",
        "# Convert Xtrain to PyTorch tensor\n",
        "Xtrain_tensor = torch.tensor(Xtrain.values, dtype=torch.float32)\n",
        "y_predicted = model(Xtrain_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.detach().numpy()\n",
        "r2 = r2_score(ytrain, y_predicted)\n",
        "print(\"R-squared Train:\", r2)\n",
        "\n",
        "# Convert Xtest to PyTorch tensor\n",
        "Xtest_tensor = torch.tensor(Xtest.values, dtype=torch.float32)\n",
        "y_predicted = model(Xtest_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.detach().numpy()\n",
        "r2 = r2_score(ytest, y_predicted)\n",
        "print(\"R-squared Test:\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXlZlj1zDSZ3"
      },
      "source": [
        "# Now Tensorflow API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3vMntjoDVX1",
        "outputId": "4ed36683-ef96-4917-e13b-0d1594ee5fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time (10): elapsed_time=150.23390531539917 seconds\n",
            "Training time (20): elapsed_time=299.1795496940613 seconds\n",
            "Training time (20): elapsed_time=299.17985486984253 seconds\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "# Define the model structure using TensorFlow and tf.Variable\n",
        "class Net(tf.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.w1 = tf.Variable(tf.random.normal([6, 256]))\n",
        "    self.b1 = tf.Variable(tf.zeros([256]))\n",
        "    self.w2 = tf.Variable(tf.random.normal([256, 128]))\n",
        "    self.b2 = tf.Variable(tf.zeros([128]))\n",
        "    self.w3 = tf.Variable(tf.random.normal([128, 64]))\n",
        "    self.b3 = tf.Variable(tf.zeros([64]))\n",
        "    self.w4 = tf.Variable(tf.random.normal([64, 1]))\n",
        "    self.b4 = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = tf.nn.relu(tf.matmul(x, self.w1) + self.b1)\n",
        "    x = tf.nn.relu(tf.matmul(x, self.w2) + self.b2)\n",
        "    x = tf.nn.relu(tf.matmul(x, self.w3) + self.b3)\n",
        "    x = tf.matmul(x, self.w4) + self.b4\n",
        "    return x\n",
        "\n",
        "# Create an instance of the model\n",
        "model = Net()\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "criterion = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "# Convert data to TensorFlow tensors\n",
        "Xtrain_tensor = tf.convert_to_tensor(Xtrain.values, dtype=tf.float32)\n",
        "ytrain_tensor = tf.convert_to_tensor(ytrain.values, dtype=tf.float32)\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "batch_size = 100\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "  for i in range(0, len(Xtrain_tensor), batch_size):\n",
        "    # Get batch of data\n",
        "    Xbatch = Xtrain_tensor[i:i+batch_size]\n",
        "    ybatch = ytrain_tensor[i:i+batch_size]\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Forward pass\n",
        "      outputs = model(Xbatch)\n",
        "      loss = criterion(ybatch, outputs)  # Calculate loss within GradientTape context\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    if gradients:\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    else:\n",
        "        print(\"No gradients to apply\")\n",
        "        break\n",
        "  if ((epoch+1)%10==0):\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Training time ({epoch+1}): {elapsed_time=} seconds\")\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Training time ({epoch+1}): {elapsed_time=} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgG-KsWzDjZL",
        "outputId": "9452bcbc-d410-41bb-8f2b-86716079a373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xtrain.shape=(37758, 6)\n",
            "R-squared Train: 0.8756208460116558\n",
            "R-squared Test: 0.8768909892161543\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Assuming 'model' is your trained TensorFlow model, 'Xtest' is your test data, and 'ytest' are the true target values\n",
        "print (f\"{Xtrain.shape=}\")\n",
        "\n",
        "# Convert Xtrain to TensorFlow tensor\n",
        "Xtrain_tensor = tf.convert_to_tensor(Xtrain.values, dtype=tf.float32)\n",
        "y_predicted = model(Xtrain_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.numpy()\n",
        "r2 = r2_score(ytrain, y_predicted)\n",
        "print(\"R-squared Train:\", r2)\n",
        "\n",
        "# Convert Xtest to TensorFlow tensor\n",
        "Xtest_tensor = tf.convert_to_tensor(Xtest.values, dtype=tf.float32)\n",
        "y_predicted = model(Xtest_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.numpy()\n",
        "r2 = r2_score(ytest, y_predicted)\n",
        "print(\"R-squared Test:\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now with GPU"
      ],
      "metadata": {
        "id": "glvaav7BVii8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "# Explicitly request a GPU if available\n",
        "with tf.device('/device:GPU:0'):  # Will fall back to CPU if no GPU is found\n",
        "\n",
        "  # Define the model structure using TensorFlow and tf.Variable\n",
        "  class Net(tf.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.w1 = tf.Variable(tf.random.normal([6, 256]))\n",
        "      self.b1 = tf.Variable(tf.zeros([256]))\n",
        "      self.w2 = tf.Variable(tf.random.normal([256, 128]))\n",
        "      self.b2 = tf.Variable(tf.zeros([128]))\n",
        "      self.w3 = tf.Variable(tf.random.normal([128, 64]))\n",
        "      self.b3 = tf.Variable(tf.zeros([64]))\n",
        "      self.w4 = tf.Variable(tf.random.normal([64, 1]))\n",
        "      self.b4 = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "    def __call__(self, x):\n",
        "      x = tf.nn.relu(tf.matmul(x, self.w1) + self.b1)\n",
        "      x = tf.nn.relu(tf.matmul(x, self.w2) + self.b2)\n",
        "      x = tf.nn.relu(tf.matmul(x, self.w3) + self.b3)\n",
        "      x = tf.matmul(x, self.w4) + self.b4\n",
        "      return x\n",
        "\n",
        "  # Create an instance of the model\n",
        "  model = Net()\n",
        "\n",
        "  # Define the optimizer and loss function\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  criterion = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "  # Convert data to TensorFlow tensors\n",
        "  Xtrain_tensor = tf.convert_to_tensor(Xtrain.values, dtype=tf.float32)\n",
        "  ytrain_tensor = tf.convert_to_tensor(ytrain.values, dtype=tf.float32)\n",
        "\n",
        "  # Train the model\n",
        "  epochs = 20\n",
        "  batch_size = 1000\n",
        "\n",
        "  start_time = time.time()\n",
        "  for epoch in range(epochs):\n",
        "    for i in range(0, len(Xtrain_tensor), batch_size):\n",
        "      # Get batch of data\n",
        "      Xbatch = Xtrain_tensor[i:i+batch_size]\n",
        "      ybatch = ytrain_tensor[i:i+batch_size]\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "        # Forward pass\n",
        "        outputs = model(Xbatch)\n",
        "        loss = criterion(ybatch, outputs)  # Calculate loss within GradientTape context\n",
        "\n",
        "      # Backward pass and optimization\n",
        "      gradients = tape.gradient(loss, model.trainable_variables)\n",
        "      if gradients:\n",
        "          optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "      else:\n",
        "          print(\"No gradients to apply\")\n",
        "          break\n",
        "    if ((epoch+1)%10==0):\n",
        "      end_time = time.time()\n",
        "      elapsed_time = end_time - start_time\n",
        "      print(f\"Training time ({epoch+1}): {elapsed_time=} seconds\")\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(f\"Training time ({epoch+1}): {elapsed_time=} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWaBvYdAVmDw",
        "outputId": "3d5aead8-b387-4b99-da10-4c23d191ad42"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time (10): elapsed_time=15.160910606384277 seconds\n",
            "Training time (20): elapsed_time=30.69427752494812 seconds\n",
            "Training time (20): elapsed_time=30.694395065307617 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Assuming 'model' is your trained TensorFlow model, 'Xtest' is your test data, and 'ytest' are the true target values\n",
        "print (f\"{Xtrain.shape=}\")\n",
        "\n",
        "# Convert Xtrain to TensorFlow tensor\n",
        "Xtrain_tensor = tf.convert_to_tensor(Xtrain.values, dtype=tf.float32)\n",
        "y_predicted = model(Xtrain_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.numpy()\n",
        "r2 = r2_score(ytrain, y_predicted)\n",
        "print(\"R-squared Train:\", r2)\n",
        "\n",
        "# Convert Xtest to TensorFlow tensor\n",
        "Xtest_tensor = tf.convert_to_tensor(Xtest.values, dtype=tf.float32)\n",
        "y_predicted = model(Xtest_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.numpy()\n",
        "r2 = r2_score(ytest, y_predicted)\n",
        "print(\"R-squared Test:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OfZojS5Vxl4",
        "outputId": "d86dad5d-044c-4e42-8687-52567be1cdbf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xtrain.shape=(37758, 6)\n",
            "R-squared Train: 0.8700311662488012\n",
            "R-squared Test: 0.8715327263234984\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOJv2fcVFACEKnhxyatx4Bz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}