{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/everestso/Fall24Spring25/blob/main/UDL_pyTorch_DeepNetworks_with_DiamondsInColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4BKVI4dEyI0"
      },
      "source": [
        "# Deep Learning w/ Diamonds\n",
        "\n",
        "https://www.kaggle.com/datasets/shivam2503/diamonds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ-SyI7xXHPY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Define a standardization scaler to transform values\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77FkUeKH_nJ6",
        "outputId": "c80d162a-4ada-4a7b-e7c3-80640803970f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-OzEC9axnc2fTMMcHCXnBkQzypluJLLG\n",
            "To: /content/diamonds.csv\n",
            "100% 2.57M/2.57M [00:00<00:00, 18.5MB/s]\n",
            "(53940, 10)\n"
          ]
        }
      ],
      "source": [
        "!gdown 1-OzEC9axnc2fTMMcHCXnBkQzypluJLLG\n",
        "\n",
        "file_name = 'diamonds.csv'\n",
        "\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "df.head()\n",
        "print (df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Feature Model"
      ],
      "metadata": {
        "id": "07ynyuzRXYuk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ygjMjWlX-7I",
        "outputId": "2800e0bb-ab72-4de3-b965-7f98f5a10b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diamond_sample.shape=(53940, 10)\n",
            "X.columns=Index(['carat', 'cut', 'color', 'clarity'], dtype='object'), X.shape=(53940, 4)\n",
            "   carat      cut color clarity\n",
            "0   0.23    Ideal     E     SI2\n",
            "1   0.21  Premium     E     SI1\n",
            "2   0.23     Good     E     VS1\n",
            "Index(['price'], dtype='object')\n",
            "y.iloc[:3]=   price\n",
            "0    326\n",
            "1    326\n",
            "2    327\n"
          ]
        }
      ],
      "source": [
        "#diamond_sample = df.sample(30, random_state=12)\n",
        "diamond_sample = df.copy()\n",
        "print(f\"{diamond_sample.shape=}\")\n",
        "\n",
        "# Create a dataframe X containing all the features except carat, cut, and color\n",
        "drop_columns = ['depth', 'table', 'x', 'y', 'z', 'price']\n",
        "X = diamond_sample.drop(drop_columns, axis=1)\n",
        "print(f\"{X.columns=}, {X.shape=}\")\n",
        "print(f\"{X[:3]}\")\n",
        "\n",
        "\n",
        "# Create a dataframe y containing the feature price\n",
        "y = diamond_sample[['price']]\n",
        "print(f\"{y.columns}\")\n",
        "print(f\"{y.iloc[:3]=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzaWzfkwhaGm"
      },
      "source": [
        "## Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWRzU7aWhZFW",
        "outputId": "7b5534dd-f128-41b7-a772-d54aee987235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.55116139  0.97923439 -0.82538596 -0.02809222]\n",
            " [-0.84330851  0.97923439  0.34923047  1.18761651]\n",
            " [-0.82218018  0.08287491  0.93653868 -0.63594658]\n",
            " ...\n",
            " [-1.05459183  0.97923439  0.93653868 -0.02809222]\n",
            " [ 0.4243914   0.97923439 -0.23807775  0.57976215]\n",
            " [-0.18833022 -0.81348456 -1.41269417  1.79547088]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Split data into train and test sets\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "# Define a dictionary for quality mapping\n",
        "cut_quality = {'Fair': 1, 'Good': 2, 'Very Good': 3, 'Premium': 4, 'Ideal': 5}\n",
        "\n",
        "# Apply the mapping to Xtrain and Xtest\n",
        "Xtrain['cut'] = Xtrain['cut'].map(cut_quality)\n",
        "Xtest['cut'] = Xtest['cut'].map(cut_quality)\n",
        "\n",
        "# Create an OrdinalEncoder for the 'color' column\n",
        "enc = OrdinalEncoder(categories=[['J', 'I', 'H', 'G', 'F', 'E', 'D']]) # Define the order of categories\n",
        "\n",
        "# Fit the encoder on the training data and transform both training and testing data\n",
        "Xtrain['color'] = enc.fit_transform(Xtrain[['color']])\n",
        "Xtest['color'] = enc.transform(Xtest[['color']])\n",
        "\n",
        "# Create an OrdinalEncoder for the 'clarity' column\n",
        "clarity_enc = OrdinalEncoder(categories=[['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']])\n",
        "Xtrain['clarity'] = clarity_enc.fit_transform(Xtrain[['clarity']])\n",
        "Xtest['clarity'] = clarity_enc.transform(Xtest[['clarity']])\n",
        "\n",
        "Transform = StandardScaler()\n",
        "\n",
        "# Apply scaler\n",
        "Xtrain_scaled = Transform.fit_transform(Xtrain)\n",
        "Xtest_scaled = Transform.transform(Xtest)\n",
        "\n",
        "print  (Xtrain_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjPL-d4uilpp",
        "outputId": "b5daaa04-ba40-498a-f600-882680a61754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transform.mean_ = [0.79913634 3.90754277 3.40537105 3.04621537]\n",
            "Transform.scale_ = [0.47329813 1.11562384 1.70268349 1.64513091]\n",
            "Xtrain.columns[0]='carat', Transform.mean_[0]=0.7991363419672652, Transform.scale_[0]=0.47329813202512444, np.std(Xtrain[Xtrain.columns[0]])=0.47329813202512444\n",
            "Xtrain.iloc[0,0]=1.06, (Xtrain.iloc[0,0]-Transform.mean_[0])/Transform.scale_[0]=0.5511613935946977, Xtrain_scaled[0][0]=0.5511613935946977\n",
            "np.mean(Xtrain, axis=0)=carat      0.799136\n",
            "cut        3.907543\n",
            "color      3.405371\n",
            "clarity    3.046215\n",
            "dtype: float64\n",
            "np.std(Xtrain, axis=0)=carat      0.473298\n",
            "cut        1.115624\n",
            "color      1.702683\n",
            "clarity    1.645131\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# prompt: Print the transform formula details\n",
        "\n",
        "print(f\"Transform.mean_ = {Transform.mean_}\")\n",
        "print(f\"Transform.scale_ = {Transform.scale_}\")\n",
        "\n",
        "print (f\"{Xtrain.columns[0]=}, {Transform.mean_[0]=}, {Transform.scale_[0]=}, {np.std(Xtrain[Xtrain.columns[0]])=}\")\n",
        "print (f\"{Xtrain.iloc[0,0]=}, {(Xtrain.iloc[0,0]-Transform.mean_[0])/Transform.scale_[0]=}, {Xtrain_scaled[0][0]=}\")\n",
        "print (f\"{np.mean(Xtrain, axis=0)=}\")\n",
        "print (f\"{np.std(Xtrain, axis=0)=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uaIix0a2O2p"
      },
      "source": [
        "# Now pyTorch\n",
        "\n",
        "https://aibyhand.substack.com/p/6-can-you-code-a-multi-layer-perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIgUbmwB2Qsp",
        "outputId": "950c42c1-fad2-4e03-d18c-2bfac4a94409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    10, Loss 2443852209.000\n",
            "Epoch    20, Loss 2439941159.000\n",
            "Epoch    30, Loss 2422697154.000\n",
            "Epoch    40, Loss 2438498607.000\n",
            "Epoch    50, Loss 2467207017.000\n"
          ]
        }
      ],
      "source": [
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "import time\n",
        "\n",
        "# Define input size, hidden layer size, output size\n",
        "D_i, D_k, D_o = 4, 40, 1\n",
        "\n",
        "batch_size = 250\n",
        "total_epochs = 50\n",
        "lr=[0.15, 0.1, 0.05, 0.01]\n",
        "lr_i=0\n",
        "\n",
        "# Create model with two hidden layers\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(D_i, D_k),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(D_k, D_k),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(D_k, D_o)\n",
        ")\n",
        "\n",
        "# He initialization of weights\n",
        "def weights_init(layer):\n",
        "    if isinstance(layer, nn.Linear):\n",
        "        nn.init.kaiming_uniform_(layer.weight)\n",
        "        layer.bias.data.fill_(0.0)\n",
        "\n",
        "model.apply(weights_init)\n",
        "\n",
        "# Choose least squares loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "optimizers = [torch.optim.SGD(model.parameters(), lr=lr[lr_i], momentum=0.9),\n",
        "              torch.optim.Adam(model.parameters())]\n",
        "optimizers_i = 0\n",
        "\n",
        "# Construct SGD optimizer and initialize learning rate and momentum\n",
        "optimizer = optimizers[optimizers_i]\n",
        "\n",
        "# Decreases learning rate by half every 10 epochs\n",
        "#scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "# Lets Use Diamond Data\n",
        "x = torch.tensor(Xtrain_scaled, dtype=torch.float32)\n",
        "y = torch.tensor(ytrain.values, dtype=torch.float32)\n",
        "\n",
        "data_loader = DataLoader(TensorDataset(x, y), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Loop over the dataset 100 times\n",
        "for epoch in range(total_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    # Loop over batches\n",
        "    for i, data in enumerate(data_loader):\n",
        "\n",
        "        # Retrieve inputs and labels for this batch\n",
        "        x_batch, y_batch = data\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        pred = model(x_batch)\n",
        "        loss = criterion(pred, y_batch)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update statistics\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    if (epoch+1)%10==0:\n",
        "        print(f\"Epoch {epoch+1:5d}, Loss {epoch_loss:.3f}\")\n",
        "\n",
        "    # Tell scheduler to update learning rate\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URtCXoaw2Yyr",
        "outputId": "8c0c562f-282c-4402-80f5-4b3f0de8e9c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xtrain.shape=(37758, 4)\n",
            "R-squared Train: 0.9575517177581787\n",
            "R-squared Test: 0.9559349417686462\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Assuming 'model' is your trained Keras model, 'Xtest' is your test data, and 'ytest' are the true target values\n",
        "print (f\"{Xtrain.shape=}\")\n",
        "\n",
        "# Convert Xtrain to PyTorch tensor\n",
        "Xtrain_tensor = torch.tensor(Xtrain_scaled, dtype=torch.float32)\n",
        "y_predicted = model(Xtrain_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.detach().numpy()\n",
        "r2 = r2_score(ytrain, y_predicted)\n",
        "print(\"R-squared Train:\", r2)\n",
        "\n",
        "# Convert Xtest to PyTorch tensor\n",
        "Xtest_tensor = torch.tensor(Xtest_scaled, dtype=torch.float32)\n",
        "y_predicted = model(Xtest_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.detach().numpy()\n",
        "r2 = r2_score(ytest, y_predicted)\n",
        "print(\"R-squared Test:\", r2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMFBSBGs35gE2JxY5RYIj6r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}