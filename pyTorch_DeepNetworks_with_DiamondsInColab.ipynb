{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/everestso/Fall24Spring25/blob/main/pyTorch_DeepNetworks_with_DiamondsInColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4BKVI4dEyI0"
      },
      "source": [
        "# Deep Learning w/ Diamonds\n",
        "\n",
        "https://www.kaggle.com/datasets/shivam2503/diamonds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AJ-SyI7xXHPY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77FkUeKH_nJ6",
        "outputId": "2452b5de-e8f6-4f53-ad6c-2c6ebef1b048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-OzEC9axnc2fTMMcHCXnBkQzypluJLLG\n",
            "To: /content/diamonds.csv\n",
            "\r  0% 0.00/2.57M [00:00<?, ?B/s]\r100% 2.57M/2.57M [00:00<00:00, 267MB/s]\n",
            "(53940, 10)\n"
          ]
        }
      ],
      "source": [
        "!gdown 1-OzEC9axnc2fTMMcHCXnBkQzypluJLLG\n",
        "\n",
        "file_name = 'diamonds.csv'\n",
        "\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "df.head()\n",
        "print (df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ygjMjWlX-7I",
        "outputId": "0fe486a0-812c-4cb1-a7dd-3630decc3492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diamond_sample.shape=(53940, 10)\n",
            "X.columns=Index(['carat', 'cut', 'color'], dtype='object'), X.shape=(53940, 3)\n",
            "   carat      cut color\n",
            "0   0.23    Ideal     E\n",
            "1   0.21  Premium     E\n",
            "2   0.23     Good     E\n",
            "Index(['price'], dtype='object')\n",
            "y.iloc[:3]=   price\n",
            "0    326\n",
            "1    326\n",
            "2    327\n"
          ]
        }
      ],
      "source": [
        "#diamond_sample = df.sample(30, random_state=12)\n",
        "diamond_sample = df.copy()\n",
        "print(f\"{diamond_sample.shape=}\")\n",
        "\n",
        "# Create a dataframe X containing all the features except carat, cut, and color\n",
        "drop_columns = ['depth', 'table', 'x', 'y', 'z', 'clarity', 'price']\n",
        "X = diamond_sample.drop(drop_columns, axis=1)\n",
        "print(f\"{X.columns=}, {X.shape=}\")\n",
        "print(f\"{X[:3]}\")\n",
        "\n",
        "\n",
        "# Create a dataframe y containing the feature price\n",
        "y = diamond_sample[['price']]\n",
        "print(f\"{y.columns}\")\n",
        "print(f\"{y.iloc[:3]=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzaWzfkwhaGm"
      },
      "source": [
        "## Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWRzU7aWhZFW",
        "outputId": "6045ddbe-7da5-4826-9c2a-da540a82a6ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.55116139  0.97923439 -0.82538596]\n",
            " [-0.84330851  0.97923439  0.34923047]\n",
            " [-0.82218018  0.08287491  0.93653868]\n",
            " ...\n",
            " [-1.05459183  0.97923439  0.93653868]\n",
            " [ 0.4243914   0.97923439 -0.23807775]\n",
            " [-0.18833022 -0.81348456 -1.41269417]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Define a standardization scaler to transform values\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Split data into train and test sets\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "# Define a dictionary for quality mapping\n",
        "cut_quality = {'Fair': 1, 'Good': 2, 'Very Good': 3, 'Premium': 4, 'Ideal': 5}\n",
        "\n",
        "# Apply the mapping to Xtrain and Xtest\n",
        "Xtrain['cut'] = Xtrain['cut'].map(cut_quality)\n",
        "Xtest['cut'] = Xtest['cut'].map(cut_quality)\n",
        "\n",
        "# Create an OrdinalEncoder for the 'color' column\n",
        "enc = OrdinalEncoder(categories=[['J', 'I', 'H', 'G', 'F', 'E', 'D']]) # Define the order of categories\n",
        "\n",
        "# Fit the encoder on the training data and transform both training and testing data\n",
        "Xtrain['color'] = enc.fit_transform(Xtrain[['color']])\n",
        "Xtest['color'] = enc.transform(Xtest[['color']])\n",
        "\n",
        "Transform = StandardScaler()\n",
        "\n",
        "# Apply scaler\n",
        "Xtrain_scaled = Transform.fit_transform(Xtrain)\n",
        "Xtest_scaled = Transform.transform(Xtest)\n",
        "\n",
        "print  (Xtrain_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjPL-d4uilpp",
        "outputId": "c3dc700a-609d-4c64-99db-234106940fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transform.mean_ = [0.79913634 3.90754277 3.40537105]\n",
            "Transform.scale_ = [0.47329813 1.11562384 1.70268349]\n",
            "Xtrain.columns[0]='carat', Transform.mean_[0]=0.7991363419672652, Transform.scale_[0]=0.47329813202512444, np.std(Xtrain[Xtrain.columns[0]])=0.47329813202512444\n",
            "Xtrain.iloc[0,0]=1.06, (Xtrain.iloc[0,0]-Transform.mean_[0])/Transform.scale_[0]=0.5511613935946977, Xtrain_scaled[0][0]=0.5511613935946977\n",
            "np.mean(Xtrain, axis=0)=carat    0.799136\n",
            "cut      3.907543\n",
            "color    3.405371\n",
            "dtype: float64\n",
            "np.std(Xtrain, axis=0)=carat    0.473298\n",
            "cut      1.115624\n",
            "color    1.702683\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# prompt: Print the transform formula details\n",
        "\n",
        "print(f\"Transform.mean_ = {Transform.mean_}\")\n",
        "print(f\"Transform.scale_ = {Transform.scale_}\")\n",
        "\n",
        "print (f\"{Xtrain.columns[0]=}, {Transform.mean_[0]=}, {Transform.scale_[0]=}, {np.std(Xtrain[Xtrain.columns[0]])=}\")\n",
        "print (f\"{Xtrain.iloc[0,0]=}, {(Xtrain.iloc[0,0]-Transform.mean_[0])/Transform.scale_[0]=}, {Xtrain_scaled[0][0]=}\")\n",
        "print (f\"{np.mean(Xtrain, axis=0)=}\")\n",
        "print (f\"{np.std(Xtrain, axis=0)=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uaIix0a2O2p"
      },
      "source": [
        "# Now pyTorch\n",
        "\n",
        "https://aibyhand.substack.com/p/6-can-you-code-a-multi-layer-perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIgUbmwB2Qsp",
        "outputId": "668fbe46-8727-48a5-e597-591cc4276ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time (10): elapsed_time=4.3379435539245605 seconds, Loss: 961474.9375\n",
            "Training time (20): elapsed_time=8.670960187911987 seconds, Loss: 872019.0625\n",
            "Training time (30): elapsed_time=13.118133068084717 seconds, Loss: 845679.5000\n",
            "Training time (40): elapsed_time=17.429007053375244 seconds, Loss: 840067.0625\n",
            "Training time (50): elapsed_time=21.805064916610718 seconds, Loss: 830470.2500\n",
            "Training time (60): elapsed_time=26.454598665237427 seconds, Loss: 822546.6875\n",
            "Training time (70): elapsed_time=30.799639463424683 seconds, Loss: 817568.1250\n",
            "Training time (80): elapsed_time=35.28777742385864 seconds, Loss: 816712.6875\n",
            "Training time (90): elapsed_time=39.657697677612305 seconds, Loss: 813717.4375\n",
            "Training time (100): elapsed_time=43.94639849662781 seconds, Loss: 811830.5000\n",
            "Training time (110): elapsed_time=48.30076551437378 seconds, Loss: 810532.0625\n",
            "Training time (120): elapsed_time=52.560551404953 seconds, Loss: 809776.5000\n",
            "Training time (130): elapsed_time=56.88023924827576 seconds, Loss: 809245.7500\n",
            "Training time (130): elapsed_time=56.88050985336304 seconds\n",
            "Predictions: [[ 9326.653]\n",
            " [12332.577]\n",
            " [12109.073]]\n",
            "Actual values:        price\n",
            "32685    802\n",
            "36258    935\n",
            "14429   5826\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "status = 10\n",
        "\n",
        "# Define the model structure using nn.Sequential\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(3, 4, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(4, 2, bias = False),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(2, 5, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(5, 1)\n",
        ")\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "Xtrain_tensor = torch.tensor(Xtrain_scaled, dtype=torch.float32)\n",
        "ytrain_tensor = torch.tensor(ytrain.values, dtype=torch.float32)\n",
        "\n",
        "# Train the model\n",
        "epochs = 130\n",
        "batch_size = 100\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "  for i in range(0, len(Xtrain_tensor), batch_size):\n",
        "    # Get batch of data\n",
        "    Xbatch = Xtrain_tensor[i:i+batch_size]\n",
        "    ybatch = ytrain_tensor[i:i+batch_size]\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(Xbatch)\n",
        "    loss = criterion(outputs, ybatch)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if ((epoch+1)%10==0):\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Training time ({epoch+1}): {elapsed_time=} seconds, Loss: {loss.item():.4f}\") # Print loss with training time\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Training time ({epoch+1}): {elapsed_time=} seconds\")\n",
        "\n",
        "# Convert test data to PyTorch tensors\n",
        "Xtest_tensor = torch.tensor(Xtest.values, dtype=torch.float32)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model(Xtest_tensor[:3])\n",
        "\n",
        "# Convert predictions to numpy array\n",
        "predictions = predictions.detach().numpy()\n",
        "\n",
        "print('Predictions:', predictions.round(3))\n",
        "print('Actual values:', ytest[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URtCXoaw2Yyr",
        "outputId": "86816aa4-05d3-4a79-85af-40bbb3278b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xtrain.shape=(37758, 3)\n",
            "R-squared Train: 0.8859268504506055\n",
            "R-squared Test: 0.8853695330034252\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Assuming 'model' is your trained Keras model, 'Xtest' is your test data, and 'ytest' are the true target values\n",
        "print (f\"{Xtrain.shape=}\")\n",
        "\n",
        "# Convert Xtrain to PyTorch tensor\n",
        "Xtrain_tensor = torch.tensor(Xtrain_scaled, dtype=torch.float32)\n",
        "y_predicted = model(Xtrain_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.detach().numpy()\n",
        "r2 = r2_score(ytrain, y_predicted)\n",
        "print(\"R-squared Train:\", r2)\n",
        "\n",
        "# Convert Xtest to PyTorch tensor\n",
        "Xtest_tensor = torch.tensor(Xtest_scaled, dtype=torch.float32)\n",
        "y_predicted = model(Xtest_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.detach().numpy()\n",
        "r2 = r2_score(ytest, y_predicted)\n",
        "print(\"R-squared Test:\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try 4 C's\n"
      ],
      "metadata": {
        "id": "ERKB6WGURXhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#diamond_sample = df.sample(30, random_state=12)\n",
        "diamond_sample = df.copy()\n",
        "print(f\"{diamond_sample.shape=}\")\n",
        "\n",
        "# Create a dataframe X containing all the features except carat, cut, color, clarity.\n",
        "drop_columns = ['depth', 'table', 'x', 'y', 'z', 'price']\n",
        "X = diamond_sample.drop(drop_columns, axis=1)\n",
        "print(f\"{X.columns=}, {X.shape=}\")\n",
        "print(f\"{X[:3]}\")\n",
        "\n",
        "\n",
        "# Create a dataframe y containing the feature price\n",
        "y = diamond_sample[['price']]\n",
        "print(f\"{y.columns}\")\n",
        "print(f\"{y.iloc[:3]=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7Il3drfRezW",
        "outputId": "10c2afaa-de69-429c-9b1a-1f71f8eeb281"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diamond_sample.shape=(53940, 10)\n",
            "X.columns=Index(['carat', 'cut', 'color', 'clarity'], dtype='object'), X.shape=(53940, 4)\n",
            "   carat      cut color clarity\n",
            "0   0.23    Ideal     E     SI2\n",
            "1   0.21  Premium     E     SI1\n",
            "2   0.23     Good     E     VS1\n",
            "Index(['price'], dtype='object')\n",
            "y.iloc[:3]=   price\n",
            "0    326\n",
            "1    326\n",
            "2    327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "# Define a dictionary for quality mapping\n",
        "cut_quality = {'Fair': 1, 'Good': 2, 'Very Good': 3, 'Premium': 4, 'Ideal': 5}\n",
        "\n",
        "# Apply the mapping to Xtrain and Xtest\n",
        "Xtrain['cut'] = Xtrain['cut'].map(cut_quality)\n",
        "Xtest['cut'] = Xtest['cut'].map(cut_quality)\n",
        "\n",
        "# Create an OrdinalEncoder for the 'color' column\n",
        "enc = OrdinalEncoder(categories=[['J', 'I', 'H', 'G', 'F', 'E', 'D']]) # Define the order of categories\n",
        "\n",
        "# Fit the encoder on the training data and transform both training and testing data\n",
        "Xtrain['color'] = enc.fit_transform(Xtrain[['color']])\n",
        "Xtest['color'] = enc.transform(Xtest[['color']])\n",
        "\n",
        "# Create an OrdinalEncoder for the 'clarity' column\n",
        "clarity_enc = OrdinalEncoder(categories=[['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']])\n",
        "\n",
        "# Fit the encoder on the training data and transform both training and testing data\n",
        "Xtrain['clarity'] = clarity_enc.fit_transform(Xtrain[['clarity']])\n",
        "Xtest['clarity'] = clarity_enc.transform(Xtest[['clarity']])\n",
        "\n",
        "Transform = StandardScaler()\n",
        "\n",
        "# Apply scaler\n",
        "Xtrain_scaled = Transform.fit_transform(Xtrain)\n",
        "Xtest_scaled = Transform.transform(Xtest)\n",
        "\n",
        "print  (Xtrain_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHJvUTAcR5f_",
        "outputId": "526f455f-b76a-44c6-da3a-1239fcf6539a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.55116139  0.97923439 -0.82538596 -0.02809222]\n",
            " [-0.84330851  0.97923439  0.34923047  1.18761651]\n",
            " [-0.82218018  0.08287491  0.93653868 -0.63594658]\n",
            " ...\n",
            " [-1.05459183  0.97923439  0.93653868 -0.02809222]\n",
            " [ 0.4243914   0.97923439 -0.23807775  0.57976215]\n",
            " [-0.18833022 -0.81348456 -1.41269417  1.79547088]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "status = 10\n",
        "\n",
        "# Define the model structure using nn.Sequential\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 4, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(4, 2, bias = False),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(2, 5, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(5, 1)\n",
        ")\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "Xtrain_tensor = torch.tensor(Xtrain_scaled, dtype=torch.float32)\n",
        "ytrain_tensor = torch.tensor(ytrain.values, dtype=torch.float32)\n",
        "\n",
        "# Train the model\n",
        "epochs = 130\n",
        "batch_size = 100\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "  for i in range(0, len(Xtrain_tensor), batch_size):\n",
        "    # Get batch of data\n",
        "    Xbatch = Xtrain_tensor[i:i+batch_size]\n",
        "    ybatch = ytrain_tensor[i:i+batch_size]\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(Xbatch)\n",
        "    loss = criterion(outputs, ybatch)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if ((epoch+1)%10==0):\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Training time ({epoch+1}): {elapsed_time=} seconds, Loss: {loss.item():.4f}\") # Print loss with training time\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Training time ({epoch+1}): {elapsed_time=} seconds\")\n",
        "\n",
        "# Convert test data to PyTorch tensors\n",
        "Xtest_tensor = torch.tensor(Xtest.values, dtype=torch.float32)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model(Xtest_tensor[:3])\n",
        "\n",
        "# Convert predictions to numpy array\n",
        "predictions = predictions.detach().numpy()\n",
        "\n",
        "print('Predictions:', predictions.round(3))\n",
        "print('Actual values:', ytest[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I3wMTFiR-X3",
        "outputId": "b8e13f62-21b4-40e0-c769-ef2776bbec58"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time (10): elapsed_time=4.6828391551971436 seconds, Loss: 623406.7500\n",
            "Training time (20): elapsed_time=9.145548343658447 seconds, Loss: 518124.0000\n",
            "Training time (30): elapsed_time=13.662511825561523 seconds, Loss: 489427.9375\n",
            "Training time (40): elapsed_time=18.270651817321777 seconds, Loss: 512963.6562\n",
            "Training time (50): elapsed_time=22.954044342041016 seconds, Loss: 515371.4688\n",
            "Training time (60): elapsed_time=27.534481525421143 seconds, Loss: 506927.0938\n",
            "Training time (70): elapsed_time=31.873916149139404 seconds, Loss: 504640.6875\n",
            "Training time (80): elapsed_time=36.25572609901428 seconds, Loss: 503994.8750\n",
            "Training time (90): elapsed_time=40.5290789604187 seconds, Loss: 503789.7188\n",
            "Training time (100): elapsed_time=44.806037187576294 seconds, Loss: 503736.5312\n",
            "Training time (110): elapsed_time=49.23063039779663 seconds, Loss: 503801.0938\n",
            "Training time (120): elapsed_time=53.63481664657593 seconds, Loss: 503903.7188\n",
            "Training time (130): elapsed_time=58.04401445388794 seconds, Loss: 504017.6250\n",
            "Training time (130): elapsed_time=58.04435205459595 seconds\n",
            "Predictions: [[17981.035]\n",
            " [16386.174]\n",
            " [17399.56 ]]\n",
            "Actual values:        price\n",
            "32685    802\n",
            "36258    935\n",
            "14429   5826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Assuming 'model' is your trained Keras model, 'Xtest' is your test data, and 'ytest' are the true target values\n",
        "print (f\"{Xtrain_scaled.shape=}\")\n",
        "\n",
        "# Convert Xtrain to PyTorch tensor\n",
        "Xtrain_tensor = torch.tensor(Xtrain_scaled, dtype=torch.float32)\n",
        "y_predicted = model(Xtrain_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.detach().numpy()\n",
        "r2 = r2_score(ytrain, y_predicted)\n",
        "print(\"R-squared Train:\", r2)\n",
        "\n",
        "# Convert Xtest to PyTorch tensor\n",
        "Xtest_tensor = torch.tensor(Xtest_scaled, dtype=torch.float32)\n",
        "y_predicted = model(Xtest_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.detach().numpy()\n",
        "r2 = r2_score(ytest, y_predicted)\n",
        "print(\"R-squared Test:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqoa3-vsSFQZ",
        "outputId": "2fbe19d9-133c-4d4f-849c-603c67ec3cf2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xtrain_scaled.shape=(37758, 4)\n",
            "R-squared Train: 0.9436782179350288\n",
            "R-squared Test: 0.9421347493127947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try more features\n"
      ],
      "metadata": {
        "id": "og7RwhcXMbtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#diamond_sample = df.sample(30, random_state=12)\n",
        "diamond_sample = df.copy()\n",
        "print(f\"{diamond_sample.shape=}\")\n",
        "\n",
        "# Create a dataframe X containing all the features except cut, color, clarity, and price\n",
        "drop_columns = ['price']\n",
        "X = diamond_sample.drop(drop_columns, axis=1)\n",
        "print(f\"{X.columns=}, {X.shape=}\")\n",
        "print(f\"{X[:3]}\")\n",
        "\n",
        "\n",
        "# Create a dataframe y containing the feature price\n",
        "y = diamond_sample[['price']]\n",
        "print(f\"{y.columns}\")\n",
        "print(f\"{y.iloc[:3]=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztUogA19MdfE",
        "outputId": "a3013bad-ce3a-4bac-872a-7b209265301e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diamond_sample.shape=(53940, 10)\n",
            "X.columns=Index(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'x', 'y', 'z'], dtype='object'), X.shape=(53940, 9)\n",
            "   carat      cut color clarity  depth  table     x     y     z\n",
            "0   0.23    Ideal     E     SI2   61.5   55.0  3.95  3.98  2.43\n",
            "1   0.21  Premium     E     SI1   59.8   61.0  3.89  3.84  2.31\n",
            "2   0.23     Good     E     VS1   56.9   65.0  4.05  4.07  2.31\n",
            "Index(['price'], dtype='object')\n",
            "y.iloc[:3]=   price\n",
            "0    326\n",
            "1    326\n",
            "2    327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "# Define a dictionary for quality mapping\n",
        "cut_quality = {'Fair': 1, 'Good': 2, 'Very Good': 3, 'Premium': 4, 'Ideal': 5}\n",
        "\n",
        "# Apply the mapping to Xtrain and Xtest\n",
        "Xtrain['cut'] = Xtrain['cut'].map(cut_quality)\n",
        "Xtest['cut'] = Xtest['cut'].map(cut_quality)\n",
        "\n",
        "# Create an OrdinalEncoder for the 'color' column\n",
        "enc = OrdinalEncoder(categories=[['J', 'I', 'H', 'G', 'F', 'E', 'D']]) # Define the order of categories\n",
        "\n",
        "# Fit the encoder on the training data and transform both training and testing data\n",
        "Xtrain['color'] = enc.fit_transform(Xtrain[['color']])\n",
        "Xtest['color'] = enc.transform(Xtest[['color']])\n",
        "\n",
        "# Create an OrdinalEncoder for the 'clarity' column\n",
        "clarity_enc = OrdinalEncoder(categories=[['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']])\n",
        "\n",
        "# Fit the encoder on the training data and transform both training and testing data\n",
        "Xtrain['clarity'] = clarity_enc.fit_transform(Xtrain[['clarity']])\n",
        "Xtest['clarity'] = clarity_enc.transform(Xtest[['clarity']])\n",
        "\n",
        "Transform = StandardScaler()\n",
        "\n",
        "# Apply scaler\n",
        "Xtrain_scaled = Transform.fit_transform(Xtrain)\n",
        "Xtest_scaled = Transform.transform(Xtest)\n",
        "\n",
        "print  (Xtrain_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6s2TTAAMphV",
        "outputId": "58b80300-4a2b-4bfc-f712-7aeb6cedb17b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.55116139  0.97923439 -0.82538596 ...  0.79886224  0.74694202\n",
            "   0.64630735]\n",
            " [-0.84330851  0.97923439  0.34923047 ... -0.87788733 -0.83947701\n",
            "  -0.81830926]\n",
            " [-0.82218018  0.08287491  0.93653868 ... -0.77086076 -0.77012536\n",
            "  -0.95913778]\n",
            " ...\n",
            " [-1.05459183  0.97923439  0.93653868 ... -1.27923696 -1.22091109\n",
            "  -1.21262911]\n",
            " [ 0.4243914   0.97923439 -0.23807775 ...  0.55805246  0.50421124\n",
            "   0.6322245 ]\n",
            " [-0.18833022 -0.81348456 -1.41269417 ... -0.07518807 -0.04193302\n",
            "   0.06891042]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "status = 10\n",
        "\n",
        "# Define the model structure using nn.Sequential\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(9, 4, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(4, 2, bias = False),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(2, 5, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(5, 1)\n",
        ")\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "Xtrain_tensor = torch.tensor(Xtrain_scaled, dtype=torch.float32)\n",
        "ytrain_tensor = torch.tensor(ytrain.values, dtype=torch.float32)\n",
        "\n",
        "# Train the model\n",
        "epochs = 130\n",
        "batch_size = 100\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "  for i in range(0, len(Xtrain_tensor), batch_size):\n",
        "    # Get batch of data\n",
        "    Xbatch = Xtrain_tensor[i:i+batch_size]\n",
        "    ybatch = ytrain_tensor[i:i+batch_size]\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(Xbatch)\n",
        "    loss = criterion(outputs, ybatch)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if ((epoch+1)%10==0):\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Training time ({epoch+1}): {elapsed_time=} seconds, Loss: {loss.item():.4f}\") # Print loss with training time\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Training time ({epoch+1}): {elapsed_time=} seconds\")\n",
        "\n",
        "# Convert test data to PyTorch tensors\n",
        "Xtest_tensor = torch.tensor(Xtest.values, dtype=torch.float32)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model(Xtest_tensor[:3])\n",
        "\n",
        "# Convert predictions to numpy array\n",
        "predictions = predictions.detach().numpy()\n",
        "\n",
        "print('Predictions:', predictions.round(3))\n",
        "print('Actual values:', ytest[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMELi7iiNIS3",
        "outputId": "a9b018da-f615-47da-9890-548a019fdfa7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time (10): elapsed_time=4.277407646179199 seconds, Loss: 562195.3750\n",
            "Training time (20): elapsed_time=8.632644891738892 seconds, Loss: 639430.6875\n",
            "Training time (30): elapsed_time=12.931382656097412 seconds, Loss: 623241.6250\n",
            "Training time (40): elapsed_time=17.280531883239746 seconds, Loss: 583849.2500\n",
            "Training time (50): elapsed_time=21.61224365234375 seconds, Loss: 525784.4375\n",
            "Training time (60): elapsed_time=25.880529642105103 seconds, Loss: 500532.4688\n",
            "Training time (70): elapsed_time=30.201783895492554 seconds, Loss: 496160.7500\n",
            "Training time (80): elapsed_time=34.451969385147095 seconds, Loss: 494125.3750\n",
            "Training time (90): elapsed_time=38.69642782211304 seconds, Loss: 503100.6250\n",
            "Training time (100): elapsed_time=42.98260140419006 seconds, Loss: 517033.3750\n",
            "Training time (110): elapsed_time=47.37083554267883 seconds, Loss: 526923.3125\n",
            "Training time (120): elapsed_time=51.731287717819214 seconds, Loss: 526414.5000\n",
            "Training time (130): elapsed_time=56.03997850418091 seconds, Loss: 525614.2500\n",
            "Training time (130): elapsed_time=56.04028296470642 seconds\n",
            "Predictions: [[35329.008]\n",
            " [35361.914]\n",
            " [41602.914]]\n",
            "Actual values:        price\n",
            "32685    802\n",
            "36258    935\n",
            "14429   5826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Assuming 'model' is your trained Keras model, 'Xtest' is your test data, and 'ytest' are the true target values\n",
        "print (f\"{Xtrain_scaled.shape=}\")\n",
        "\n",
        "# Convert Xtrain to PyTorch tensor\n",
        "Xtrain_tensor = torch.tensor(Xtrain_scaled, dtype=torch.float32)\n",
        "y_predicted = model(Xtrain_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.detach().numpy()\n",
        "r2 = r2_score(ytrain, y_predicted)\n",
        "print(\"R-squared Train:\", r2)\n",
        "\n",
        "# Convert Xtest to PyTorch tensor\n",
        "Xtest_tensor = torch.tensor(Xtest_scaled, dtype=torch.float32)\n",
        "y_predicted = model(Xtest_tensor)\n",
        "\n",
        "# Convert predictions back to numpy array for r2_score\n",
        "y_predicted = y_predicted.detach().numpy()\n",
        "r2 = r2_score(ytest, y_predicted)\n",
        "print(\"R-squared Test:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1Bi75AiNqkv",
        "outputId": "215fc3cd-e78d-4c3d-99db-bf4819a34642"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xtrain_scaled.shape=(37758, 9)\n",
            "R-squared Train: 0.9524080304932849\n",
            "R-squared Test: 0.9534701339094086\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNVANLCCwQVaaxGbKr/tHbW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}